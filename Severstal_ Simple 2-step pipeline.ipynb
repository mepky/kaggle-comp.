{"cells":[{"metadata":{},"cell_type":"markdown","source":"# About this kernel\n\n* **Preprocessing**: Discard all of the training data that have all 4 masks missing. We will only train on images that have at least 1 mask, so that our classifier does not overfit on empty masks.\n* **Step 1 - Discard Images**: Use the DenseNet classifier trained in [this kernel](https://www.kaggle.com/xhlulu/severstal-steel-predict-missing-masks) to predict all of the test images that will have all 4 masks missing. We will automatically set the RLEs of those images to null.\n* **Step 2 - U-Net**: Train the same model from [Simple Keras U-Net Boilerplate](https://www.kaggle.com/xhlulu/severstal-simple-keras-u-net-boilerplate) on the \"filtered\" training data. Then, perform inference only on test images that were not discarded in step 1.\n* **Submission**: We will now combine the dataframe containing the discarded test images with the dataframe containing test images predicted in step 2, and submit everything.\n\n\n## Changelog\n* V8: Changed sign of the `missing_model` threshold, since we are only keeping the ones with low probability of having no defect.\n* V9: Fixed import for the discarding CNNs, which was updated to DenseNet.\n\n\n## References\n* Data generator: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n* RLE encoding and decoding: https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n* Architecture: https://www.kaggle.com/jesperdramsch/intro-chest-xray-dicom-viz-u-nets-full-data\n* Mask encoding: https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/data\n* Step 1 Original Kernel: https://www.kaggle.com/xhlulu/severstal-steel-predict-missing-masks\n* Step 2 Original Kernel: https://www.kaggle.com/xhlulu/severstal-simple-keras-u-net-boilerplate"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport json\nimport gc\n\nimport cv2\nimport keras\nfrom keras import backend as K\nfrom keras import layers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.optimizers import Adam\nfrom keras.callbacks import Callback, ModelCheckpoint\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/severstal-steel-defect-detection/train.csv')\ntrain_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntrain_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\ntrain_df['hasMask'] = ~ train_df['EncodedPixels'].isna()\n\nprint(train_df.shape)\ntrain_df.head()","execution_count":2,"outputs":[{"output_type":"stream","text":"(50272, 5)\n","name":"stdout"},{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"   ImageId_ClassId                                      EncodedPixels  \\\n0  0002cc93b.jpg_1  29102 12 29346 24 29602 24 29858 24 30114 24 3...   \n1  0002cc93b.jpg_2                                                NaN   \n2  0002cc93b.jpg_3                                                NaN   \n3  0002cc93b.jpg_4                                                NaN   \n4  00031f466.jpg_1                                                NaN   \n\n         ImageId ClassId  hasMask  \n0  0002cc93b.jpg       1     True  \n1  0002cc93b.jpg       2    False  \n2  0002cc93b.jpg       3    False  \n3  0002cc93b.jpg       4    False  \n4  00031f466.jpg       1    False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId_ClassId</th>\n      <th>EncodedPixels</th>\n      <th>ImageId</th>\n      <th>ClassId</th>\n      <th>hasMask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0002cc93b.jpg_1</td>\n      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n      <td>0002cc93b.jpg</td>\n      <td>1</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0002cc93b.jpg_2</td>\n      <td>NaN</td>\n      <td>0002cc93b.jpg</td>\n      <td>2</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0002cc93b.jpg_3</td>\n      <td>NaN</td>\n      <td>0002cc93b.jpg</td>\n      <td>3</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0002cc93b.jpg_4</td>\n      <td>NaN</td>\n      <td>0002cc93b.jpg</td>\n      <td>4</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00031f466.jpg_1</td>\n      <td>NaN</td>\n      <td>00031f466.jpg</td>\n      <td>1</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_count_df = train_df.groupby('ImageId').agg(np.sum).reset_index()\nmask_count_df.sort_values('hasMask', ascending=False, inplace=True)\nprint(mask_count_df.shape)\nmask_count_df.head()","execution_count":3,"outputs":[{"output_type":"stream","text":"(12568, 2)\n","name":"stdout"},{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"             ImageId  hasMask\n10803  db4867ee8.jpg      3.0\n11776  ef24da2ba.jpg      3.0\n6284   7f30b9c64.jpg      2.0\n9421   bf0c81db6.jpg      2.0\n9615   c314f43f3.jpg      2.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId</th>\n      <th>hasMask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10803</th>\n      <td>db4867ee8.jpg</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>11776</th>\n      <td>ef24da2ba.jpg</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>6284</th>\n      <td>7f30b9c64.jpg</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>9421</th>\n      <td>bf0c81db6.jpg</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>9615</th>\n      <td>c314f43f3.jpg</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv('../input/severstal-steel-defect-detection/sample_submission.csv')\nsub_df['ImageId'] = sub_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntest_imgs = pd.DataFrame(sub_df['ImageId'].unique(), columns=['ImageId'])\ntest_imgs.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"         ImageId\n0  004f40c73.jpg\n1  006f39c41.jpg\n2  00b7fb703.jpg\n3  00bbcd9af.jpg\n4  0108ce457.jpg","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>004f40c73.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>006f39c41.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00b7fb703.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00bbcd9af.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0108ce457.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"non_missing_train_idx = mask_count_df[mask_count_df['hasMask'] > 0]\nnon_missing_train_idx.head()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"             ImageId  hasMask\n10803  db4867ee8.jpg      3.0\n11776  ef24da2ba.jpg      3.0\n6284   7f30b9c64.jpg      2.0\n9421   bf0c81db6.jpg      2.0\n9615   c314f43f3.jpg      2.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId</th>\n      <th>hasMask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10803</th>\n      <td>db4867ee8.jpg</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>11776</th>\n      <td>ef24da2ba.jpg</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>6284</th>\n      <td>7f30b9c64.jpg</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>9421</th>\n      <td>bf0c81db6.jpg</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>9615</th>\n      <td>c314f43f3.jpg</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Step 1: Remove test images without defects\n\nMost of the stuff below is hidden, since it's copied from my previous kernels."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def load_img(code, base, resize=True):\n    path = f'{base}/{code}'\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    if resize:\n        img = cv2.resize(img, (256, 256))\n    \n    return img\n\ndef validate_path(path):\n    if not os.path.exists(path):\n        os.makedirs(path)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"BATCH_SIZE = 64\ndef create_test_gen():\n    return ImageDataGenerator(rescale=1/255.).flow_from_dataframe(\n        test_imgs,\n        directory='../input/severstal-steel-defect-detection/test_images',\n        x_col='ImageId',\n        class_mode=None,\n        target_size=(256, 256),\n        batch_size=BATCH_SIZE,\n        shuffle=False\n    )\n\ntest_gen = create_test_gen()","execution_count":7,"outputs":[{"output_type":"stream","text":"Found 1801 validated image filenames.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"remove_model = load_model('../input/severstal-predict-missing-masks/model.h5')\nremove_model.summary()","execution_count":8,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndensenet121 (Model)          (None, 8, 8, 1024)        7037504   \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 1024)              0         \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 1024)              4096      \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 1024)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               524800    \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 512)               2048      \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 513       \n=================================================================\nTotal params: 7,568,961\nTrainable params: 7,482,241\nNon-trainable params: 86,720\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Beware: Messy code below!"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_missing_pred = remove_model.predict_generator(\n    test_gen,\n    steps=len(test_gen),\n    verbose=1\n)\n\ntest_imgs['allMissing'] = test_missing_pred\ntest_imgs.head()","execution_count":9,"outputs":[{"output_type":"stream","text":"29/29 [==============================] - 19s 653ms/step\n","name":"stdout"},{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"         ImageId  allMissing\n0  004f40c73.jpg    0.507990\n1  006f39c41.jpg    1.000000\n2  00b7fb703.jpg    0.999988\n3  00bbcd9af.jpg    0.000036\n4  0108ce457.jpg    1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId</th>\n      <th>allMissing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>004f40c73.jpg</td>\n      <td>0.507990</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>006f39c41.jpg</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00b7fb703.jpg</td>\n      <td>0.999988</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00bbcd9af.jpg</td>\n      <td>0.000036</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0108ce457.jpg</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_test_imgs = test_imgs[test_imgs['allMissing'] < 0.5]\nprint(filtered_test_imgs.shape)\nfiltered_test_imgs.head()","execution_count":10,"outputs":[{"output_type":"stream","text":"(480, 2)\n","name":"stdout"},{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"          ImageId  allMissing\n3   00bbcd9af.jpg    0.000036\n5   0109b68ec.jpg    0.181035\n6   010ec96b4.jpg    0.167333\n9   01b47d973.jpg    0.001195\n18  037e7564c.jpg    0.268913","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId</th>\n      <th>allMissing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>00bbcd9af.jpg</td>\n      <td>0.000036</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0109b68ec.jpg</td>\n      <td>0.181035</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>010ec96b4.jpg</td>\n      <td>0.167333</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>01b47d973.jpg</td>\n      <td>0.001195</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>037e7564c.jpg</td>\n      <td>0.268913</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"`filtered_sub_df` contains all of the images with at least one mask. `null_sub_df` contains all the images with exactly 4 missing masks."},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_mask = sub_df['ImageId'].isin(filtered_test_imgs[\"ImageId\"].values)\nfiltered_sub_df = sub_df[filtered_mask].copy()\nnull_sub_df = sub_df[~filtered_mask].copy()\nnull_sub_df['EncodedPixels'] = null_sub_df['EncodedPixels'].apply(\n    lambda x: ' ')\n\nfiltered_sub_df.reset_index(drop=True, inplace=True)\nfiltered_test_imgs.reset_index(drop=True, inplace=True)\n\nprint(filtered_sub_df.shape)\nprint(null_sub_df.shape)\n\nfiltered_sub_df.head()","execution_count":11,"outputs":[{"output_type":"stream","text":"(1920, 3)\n(5284, 3)\n","name":"stdout"},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"   ImageId_ClassId EncodedPixels        ImageId\n0  00bbcd9af.jpg_1           1 1  00bbcd9af.jpg\n1  00bbcd9af.jpg_2           1 1  00bbcd9af.jpg\n2  00bbcd9af.jpg_3           1 1  00bbcd9af.jpg\n3  00bbcd9af.jpg_4           1 1  00bbcd9af.jpg\n4  0109b68ec.jpg_1           1 1  0109b68ec.jpg","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId_ClassId</th>\n      <th>EncodedPixels</th>\n      <th>ImageId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00bbcd9af.jpg_1</td>\n      <td>1 1</td>\n      <td>00bbcd9af.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00bbcd9af.jpg_2</td>\n      <td>1 1</td>\n      <td>00bbcd9af.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00bbcd9af.jpg_3</td>\n      <td>1 1</td>\n      <td>00bbcd9af.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00bbcd9af.jpg_4</td>\n      <td>1 1</td>\n      <td>00bbcd9af.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0109b68ec.jpg_1</td>\n      <td>1 1</td>\n      <td>0109b68ec.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Step 2: Keras U-Net\n\nMost of the stuff below is hidden, since it's copied from my previous kernels."},{"metadata":{},"cell_type":"markdown","source":"## Utility Functions"},{"metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle2mask(rle, input_shape):\n    width, height = input_shape[:2]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return mask.reshape(height, width).T\n\ndef build_masks(rles, input_shape):\n    depth = len(rles)\n    masks = np.zeros((*input_shape, depth))\n    \n    for i, rle in enumerate(rles):\n        if type(rle) is str:\n            masks[:, :, i] = rle2mask(rle, input_shape)\n    \n    return masks\n\ndef build_rles(masks):\n    width, height, depth = masks.shape\n    \n    rles = [mask2rle(masks[:, :, i])\n            for i in range(depth)]\n    \n    return rles","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Generator"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path='../input/severstal-steel-defect-detection/train_images',\n                 batch_size=32, dim=(256, 1600), n_channels=1,\n                 n_classes=4, random_state=2019, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        \n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        \n        X = self.__generate_X(list_IDs_batch)\n        \n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            return X, y\n        \n        elif self.mode == 'predict':\n            return X\n\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)\n    \n    def __generate_X(self, list_IDs_batch):\n        'Generates data containing batch_size samples'\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            img_path = f\"{self.base_path}/{im_name}\"\n            img = self.__load_grayscale(img_path)\n            \n            # Store samples\n            X[i,] = img\n\n        return X\n    \n    def __generate_y(self, list_IDs_batch):\n        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n            \n            rles = image_df['EncodedPixels'].values\n            masks = build_masks(rles, input_shape=self.dim)\n            \n            y[i, ] = masks\n\n        return y\n    \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = img.astype(np.float32) / 255.\n        img = np.expand_dims(img, axis=-1)\n\n        return img\n    \n    def __load_rgb(self, img_path):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32) / 255.\n\n        return img","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 16\n\ntrain_idx, val_idx = train_test_split(\n    non_missing_train_idx.index,  # NOTICE DIFFERENCE\n    random_state=2019, \n    test_size=0.15\n)\n\ntrain_generator = DataGenerator(\n    train_idx, \n    df=mask_count_df,\n    target_df=train_df,\n    batch_size=BATCH_SIZE, \n    n_classes=4\n)\n\nval_generator = DataGenerator(\n    val_idx, \n    df=mask_count_df,\n    target_df=train_df,\n    batch_size=BATCH_SIZE, \n    n_classes=4\n)","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def build_model(input_shape):\n    inputs = Input(input_shape)\n\n    c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (inputs)\n    c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n    p1 = MaxPooling2D((2, 2)) (c1)\n\n    c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n    c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n    p2 = MaxPooling2D((2, 2)) (c2)\n\n    c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n    c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n    p3 = MaxPooling2D((2, 2)) (c3)\n\n    c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n    c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\n    c5 = Conv2D(64, (3, 3), activation='relu', padding='same') (p4)\n    c5 = Conv2D(64, (3, 3), activation='relu', padding='same') (c5)\n    p5 = MaxPooling2D(pool_size=(2, 2)) (c5)\n\n    c55 = Conv2D(128, (3, 3), activation='relu', padding='same') (p5)\n    c55 = Conv2D(128, (3, 3), activation='relu', padding='same') (c55)\n\n    u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)\n    u6 = concatenate([u6, c5])\n    c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n    c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\n    u71 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n    u71 = concatenate([u71, c4])\n    c71 = Conv2D(32, (3, 3), activation='relu', padding='same') (u71)\n    c61 = Conv2D(32, (3, 3), activation='relu', padding='same') (c71)\n\n    u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c61)\n    u7 = concatenate([u7, c3])\n    c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n    c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\n    u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n    u8 = concatenate([u8, c2])\n    c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n    c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\n    u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n    u9 = concatenate([u9, c1], axis=3)\n    c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n    c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n\n    outputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n\n    model = Model(inputs=[inputs], outputs=[outputs])\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n    \n    return model","execution_count":16,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"model = build_model((256, 1600, 1))\nmodel.summary()","execution_count":17,"outputs":[{"output_type":"stream","text":"__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 256, 1600, 1) 0                                            \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 256, 1600, 8) 80          input_1[0][0]                    \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 256, 1600, 8) 584         conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 128, 800, 8)  0           conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 128, 800, 16) 1168        max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 128, 800, 16) 2320        conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_2 (MaxPooling2D)  (None, 64, 400, 16)  0           conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 64, 400, 32)  4640        max_pooling2d_2[0][0]            \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 64, 400, 32)  9248        conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_3 (MaxPooling2D)  (None, 32, 200, 32)  0           conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 32, 200, 64)  18496       max_pooling2d_3[0][0]            \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 32, 200, 64)  36928       conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_4 (MaxPooling2D)  (None, 16, 100, 64)  0           conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 16, 100, 64)  36928       max_pooling2d_4[0][0]            \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 16, 100, 64)  36928       conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_5 (MaxPooling2D)  (None, 8, 50, 64)    0           conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 8, 50, 128)   73856       max_pooling2d_5[0][0]            \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 8, 50, 128)   147584      conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nconv2d_transpose_1 (Conv2DTrans (None, 16, 100, 64)  32832       conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 16, 100, 128) 0           conv2d_transpose_1[0][0]         \n                                                                 conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 16, 100, 64)  73792       concatenate_1[0][0]              \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 16, 100, 64)  36928       conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nconv2d_transpose_2 (Conv2DTrans (None, 32, 200, 32)  8224        conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 32, 200, 96)  0           conv2d_transpose_2[0][0]         \n                                                                 conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 32, 200, 32)  27680       concatenate_2[0][0]              \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 32, 200, 32)  9248        conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nconv2d_transpose_3 (Conv2DTrans (None, 64, 400, 32)  4128        conv2d_16[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 64, 400, 64)  0           conv2d_transpose_3[0][0]         \n                                                                 conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 64, 400, 32)  18464       concatenate_3[0][0]              \n__________________________________________________________________________________________________\nconv2d_18 (Conv2D)              (None, 64, 400, 32)  9248        conv2d_17[0][0]                  \n__________________________________________________________________________________________________\nconv2d_transpose_4 (Conv2DTrans (None, 128, 800, 16) 2064        conv2d_18[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_4 (Concatenate)     (None, 128, 800, 32) 0           conv2d_transpose_4[0][0]         \n                                                                 conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nconv2d_19 (Conv2D)              (None, 128, 800, 16) 4624        concatenate_4[0][0]              \n__________________________________________________________________________________________________\nconv2d_20 (Conv2D)              (None, 128, 800, 16) 2320        conv2d_19[0][0]                  \n__________________________________________________________________________________________________\nconv2d_transpose_5 (Conv2DTrans (None, 256, 1600, 8) 520         conv2d_20[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_5 (Concatenate)     (None, 256, 1600, 16 0           conv2d_transpose_5[0][0]         \n                                                                 conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nconv2d_21 (Conv2D)              (None, 256, 1600, 8) 1160        concatenate_5[0][0]              \n__________________________________________________________________________________________________\nconv2d_22 (Conv2D)              (None, 256, 1600, 8) 584         conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nconv2d_23 (Conv2D)              (None, 256, 1600, 4) 36          conv2d_22[0][0]                  \n==================================================================================================\nTotal params: 600,612\nTrainable params: 600,612\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint(\n    'model.h5', \n    monitor='val_loss', \n    verbose=0, \n    save_best_only=True, \n    save_weights_only=False,\n    mode='auto'\n)\n\nhistory = model.fit_generator(\n    train_generator,\n    validation_data=val_generator,\n    callbacks=[checkpoint],\n    use_multiprocessing=False,\n    workers=1,\n    epochs=10\n)","execution_count":18,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n354/354 [==============================] - 234s 661ms/step - loss: 0.1836 - dice_coef: 0.0018 - val_loss: 0.1259 - val_dice_coef: 6.5682e-06\nEpoch 2/10\n354/354 [==============================] - 219s 619ms/step - loss: 0.1264 - dice_coef: 8.5308e-06 - val_loss: 0.1259 - val_dice_coef: 6.5682e-06\nEpoch 3/10\n354/354 [==============================] - 220s 622ms/step - loss: 0.1264 - dice_coef: 8.5308e-06 - val_loss: 0.1259 - val_dice_coef: 6.5682e-06\nEpoch 4/10\n354/354 [==============================] - 219s 619ms/step - loss: 0.1264 - dice_coef: 8.5308e-06 - val_loss: 0.1259 - val_dice_coef: 6.5682e-06\nEpoch 5/10\n354/354 [==============================] - 219s 620ms/step - loss: 0.1264 - dice_coef: 8.5308e-06 - val_loss: 0.1259 - val_dice_coef: 6.5682e-06\nEpoch 6/10\n354/354 [==============================] - 219s 618ms/step - loss: 0.1264 - dice_coef: 8.5308e-06 - val_loss: 0.1259 - val_dice_coef: 6.5682e-06\nEpoch 7/10\n354/354 [==============================] - 220s 621ms/step - loss: 0.1264 - dice_coef: 8.5308e-06 - val_loss: 0.1259 - val_dice_coef: 6.5682e-06\nEpoch 8/10\n354/354 [==============================] - 219s 620ms/step - loss: 0.1264 - dice_coef: 8.5308e-06 - val_loss: 0.1259 - val_dice_coef: 6.5682e-06\nEpoch 9/10\n354/354 [==============================] - 219s 619ms/step - loss: 0.1264 - dice_coef: 8.5308e-06 - val_loss: 0.1259 - val_dice_coef: 6.5682e-06\nEpoch 10/10\n354/354 [==============================] - 219s 618ms/step - loss: 0.1264 - dice_coef: 8.5308e-06 - val_loss: 0.1259 - val_dice_coef: 6.5682e-06\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"with open('history.json', 'w') as f:\n    json.dump(history.history, f)\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['dice_coef', 'val_dice_coef']].plot()","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f5f6f78c160>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"## Predict masks on non-discarded images"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"model.load_weights('model.h5')\ntest_df = []\n\nfor i in range(0, filtered_test_imgs.shape[0], 300):\n    batch_idx = list(\n        range(i, min(filtered_test_imgs.shape[0], i + 300))\n    )\n    \n    test_generator = DataGenerator(\n        batch_idx,\n        df=filtered_test_imgs,\n        shuffle=False,\n        mode='predict',\n        base_path='../input/severstal-steel-defect-detection/test_images',\n        target_df=filtered_sub_df,\n        batch_size=1,\n        n_classes=4\n    )\n    \n    batch_pred_masks = model.predict_generator(\n        test_generator, \n        workers=1,\n        verbose=1,\n        use_multiprocessing=False\n    )\n    \n    for j, b in tqdm(enumerate(batch_idx)):\n        filename = filtered_test_imgs['ImageId'].iloc[b]\n        image_df = filtered_sub_df[filtered_sub_df['ImageId'] == filename].copy()\n        \n        pred_masks = batch_pred_masks[j, ].round().astype(int)\n        pred_rles = build_rles(pred_masks)\n        \n        image_df['EncodedPixels'] = pred_rles\n        test_df.append(image_df)\n        \n    gc.collect()","execution_count":20,"outputs":[{"output_type":"stream","text":"300/300 [==============================] - 7s 23ms/step\n","name":"stdout"},{"output_type":"stream","text":"300it [00:04, 63.45it/s]\n","name":"stderr"},{"output_type":"stream","text":"180/180 [==============================] - 2s 14ms/step\n","name":"stdout"},{"output_type":"stream","text":"180it [00:02, 63.86it/s]\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.concat(test_df)\nprint(test_df.shape)\ntest_df.head()","execution_count":21,"outputs":[{"output_type":"stream","text":"(1920, 3)\n","name":"stdout"},{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"   ImageId_ClassId EncodedPixels        ImageId\n0  00bbcd9af.jpg_1                00bbcd9af.jpg\n1  00bbcd9af.jpg_2                00bbcd9af.jpg\n2  00bbcd9af.jpg_3                00bbcd9af.jpg\n3  00bbcd9af.jpg_4                00bbcd9af.jpg\n4  0109b68ec.jpg_1                0109b68ec.jpg","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId_ClassId</th>\n      <th>EncodedPixels</th>\n      <th>ImageId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00bbcd9af.jpg_1</td>\n      <td></td>\n      <td>00bbcd9af.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00bbcd9af.jpg_2</td>\n      <td></td>\n      <td>00bbcd9af.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00bbcd9af.jpg_3</td>\n      <td></td>\n      <td>00bbcd9af.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00bbcd9af.jpg_4</td>\n      <td></td>\n      <td>00bbcd9af.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0109b68ec.jpg_1</td>\n      <td></td>\n      <td>0109b68ec.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Now, we combine results from the predicted masks with the rest of images that our first CNN classified as having all 4 masks missing."},{"metadata":{"trusted":true},"cell_type":"code","source":"final_submission_df = pd.concat([test_df, null_sub_df])\nprint(final_submission_df.shape)\nfinal_submission_df.head()","execution_count":22,"outputs":[{"output_type":"stream","text":"(7204, 3)\n","name":"stdout"},{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"   ImageId_ClassId EncodedPixels        ImageId\n0  00bbcd9af.jpg_1                00bbcd9af.jpg\n1  00bbcd9af.jpg_2                00bbcd9af.jpg\n2  00bbcd9af.jpg_3                00bbcd9af.jpg\n3  00bbcd9af.jpg_4                00bbcd9af.jpg\n4  0109b68ec.jpg_1                0109b68ec.jpg","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId_ClassId</th>\n      <th>EncodedPixels</th>\n      <th>ImageId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00bbcd9af.jpg_1</td>\n      <td></td>\n      <td>00bbcd9af.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00bbcd9af.jpg_2</td>\n      <td></td>\n      <td>00bbcd9af.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00bbcd9af.jpg_3</td>\n      <td></td>\n      <td>00bbcd9af.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00bbcd9af.jpg_4</td>\n      <td></td>\n      <td>00bbcd9af.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0109b68ec.jpg_1</td>\n      <td></td>\n      <td>0109b68ec.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_submission_df[['ImageId_ClassId', 'EncodedPixels']].to_csv('submission.csv', index=False)","execution_count":23,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}